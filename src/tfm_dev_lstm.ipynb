{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873f1eba",
   "metadata": {},
   "source": [
    "# **MÁSTER EN FORMACIÓN PERMANENTE EN INTELIGENCIA ARTIFICIAL** \n",
    "##                      TRABAJO FIN DE MÁSTER \n",
    "### Modelo de IA para mantenimiento predictivo de activo crítico en la producción de oxígeno para diferentes industrias \n",
    "#####                Hernan Camilo Gonzalez Rodriguez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80331a2e",
   "metadata": {},
   "source": [
    "## Índice\n",
    "- [Importación de Librerias](#importacion-de-librerias)\n",
    "- [Carga de datos](#carga-de-datos)\n",
    "- [Análisis exploratorio de datos](#analisis-exploratorio-de-datos)\n",
    "- [Preparación de datos](#preparacion-de-datos)\n",
    "- [Modelo de predicción LSTM](#modelo-de-prediccion)\n",
    "- [Código métricas para evaluación del modelo](#metricas-de-evaluacion-de-modelo)\n",
    "- [Código para generar gráficas de resultados](#graficas-de-resultados)\n",
    "- [Entrenamiento del modelo](#entrenamiento-del-modelo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7639a",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Reshape, TimeDistributed, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82398eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de la semilla para reproducibilidad\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d81a4",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos y establecer la columna fecha como indice\n",
    "df = pd.read_csv(\"dataset.csv\", parse_dates=['Date'] , index_col='Date')\n",
    "df = df.sort_index()\n",
    "df_test = pd.read_csv(\"dataset_test.csv\", parse_dates=['Date'] , index_col='Date')\n",
    "df_test = df_test.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ed337",
   "metadata": {},
   "source": [
    "# Analisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d678d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la información del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion de existencia de  nulos \n",
    "print(\"Nulos en el dataset:\", df.isnull().sum().sum())\n",
    "# Validacion si hay valores nulos o faltantes\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d80be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención datos estadisticos del dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d840c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar y gráficar desbalance de  \"cOndiciones irregulares\"\n",
    "unhealthy_counts = df['Unhealthy'].value_counts()\n",
    "\n",
    "# Colores personalizados para el gráfico\n",
    "colores = ['#4CAF50', '#FF6F61']  # Verde, Rojo claro\n",
    "\n",
    "#  Gráfico de Pastel\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(unhealthy_counts, labels=unhealthy_counts.index, autopct='%1.1f%%', colors=colores)\n",
    "plt.title(\"Proporción De Condiciones Irregulares\")\n",
    "plt.legend(['0 = Condición Normal', '1 = Condición Irregular'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de barras para ver la cantidad de fallos\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Unhealthy', data=df, palette=colores)\n",
    "plt.title('Cantidad de Condiciones irregulares por Categoría')\n",
    "plt.xlabel('Condiciones Irregulares (1=si, 0=no)')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()\n",
    "\n",
    "print(\"Cantidad de condiciones irregulares por categoria:\\n\", unhealthy_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de las variables\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "fig, axs = plt.subplots(4, 2, figsize=(15, 20))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Lista de variables y sus unidades para graficar\n",
    "variables = [\n",
    "    (\"Temperature\", \"°C\"),\n",
    "    (\"Vibration\", \"Hz\"),\n",
    "    (\"Pressure\", \"Pa\"),\n",
    "    (\"Current\", \"A\"),\n",
    "    (\"Humidity\", \"°C\"),\n",
    "    (\"Caudal\", \"m³/h\")\n",
    "]\n",
    "\n",
    "for i, (var, unidad) in enumerate(variables):\n",
    "    axs[i].plot(df.index, df[var], label=var, color=\"blue\", linewidth=0.7)\n",
    "    # Resaltar los puntos donde se registró una condicion anormal\n",
    "    cA_df = df[df[\"Unhealthy\"] == 1]\n",
    "    axs[i].scatter(cA_df.index, cA_df[var], color=\"red\", s=10, label=\"Unhealthy Condition\", alpha=0.5)\n",
    "    axs[i].set_title(f\"{var} vs Time\")\n",
    "    axs[i].set_xlabel(\"Date\")\n",
    "    axs[i].set_ylabel(f\"{var} ({unidad})\")\n",
    "    axs[i].legend()\n",
    "\n",
    "# Eliminar subplots vacíos si existen\n",
    "for j in range(len(variables), len(axs)):\n",
    "    fig.delaxes(axs[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica adicional de eventos \"Unhealthy\" en el tiempo\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(df.index, df[\"Unhealthy\"], color=\"red\", linestyle=\"None\", marker=\"o\", markersize=2)\n",
    "plt.title(\"Eventos de Condiciones irregulares a lo largo del tiempo\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Condición Irreglar (1=si, 0=no)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc13f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para graficar la variable seleccionada en el rango de fechas indicado\n",
    "def graficar_variable(df, variable, fecha_inicio, fecha_fin):\n",
    "    \"\"\"\n",
    "    Grafica la variable seleccionada en el rango de fechas indicado.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con índice de fechas.\n",
    "        variable: Nombre de la columna a graficar (str).\n",
    "        fecha_inicio: Fecha de inicio (str o pd.Timestamp).\n",
    "        fecha_fin: Fecha de fin (str o pd.Timestamp).\n",
    "    \"\"\"\n",
    "    # Filtrar por rango de fechas\n",
    "    df_filtrado = df.loc[fecha_inicio:fecha_fin]\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(df_filtrado.index, df_filtrado[variable], color='blue', label=variable)\n",
    "    # Resaltar condiciones irregulares si existen\n",
    "    if 'Unhealthy' in df_filtrado.columns:\n",
    "        cA_df = df_filtrado[df_filtrado[\"Unhealthy\"] == 1]\n",
    "        plt.scatter(cA_df.index, cA_df[variable], color=\"#FF6F61\", s=20, label=\"Condición Irregular\", alpha=0.7)\n",
    "    plt.title(f\"{variable} entre {fecha_inicio} y {fecha_fin}\")\n",
    "    plt.xlabel(\"Fecha\")\n",
    "    plt.ylabel(variable)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# LLamado a la funcion \n",
    "graficar_variable(df, \"Vibration\", \"2024-03-05 00:00:00\", \"2024-03-05 23:59:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisión de outliers con boxplots\n",
    "variables = [\n",
    "    (\"Temperature\", \"°C\"),\n",
    "    (\"Vibration\", \"Hz\"),\n",
    "    (\"Pressure\", \"Pa\"),\n",
    "    (\"Current\", \"A\"),\n",
    "    (\"Humidity\", \"°C\"),\n",
    "    (\"Caudal\", \"m³/h\")\n",
    "]\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, (col, unidad) in enumerate(variables):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    sns.boxplot(x=df[col], color=\"skyblue\")\n",
    "    plt.title(f\"Boxplot de {col} ({unidad})\", fontsize=18)\n",
    "    plt.xlabel('', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de correlacion\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", cbar_kws={'label': 'Coeficiente de correlación'})\n",
    "plt.title(\"Matriz de Correlación\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67ab0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregacion de los sensores\n",
    "sensor_columns = [col for col in df.columns if col != \"Unhealthy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3da6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomposición STL\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "for sensor in sensor_columns:\n",
    "    print(f\"\\n===== Descomposición STL para: {sensor} =====\")\n",
    "    serie = df[sensor].dropna()\n",
    "\n",
    "    stl = STL(serie, period=96)  # 96 intervalos de 30 minutos (24×4).\n",
    "    result = stl.fit()\n",
    "\n",
    "    fig = result.plot()\n",
    "    fig.set_size_inches(12, 8)\n",
    "    fig.suptitle(f\"STL Decomposition - {sensor}\", fontsize=20)\n",
    "\n",
    "    # Aumentar tamaño de fuente en cada subplot\n",
    "    for ax in fig.axes:\n",
    "        ax.set_xlabel(ax.get_xlabel(), fontsize=14)\n",
    "        ax.set_ylabel(ax.get_ylabel(), fontsize=14)\n",
    "        ax.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para hacer zoom en la descomposición de un sensor\n",
    "def plot_stl_zoom(sensor_name, start_date=None, end_date=None):\n",
    "    if sensor_name not in sensor_columns:\n",
    "        print(f\"Sensor '{sensor_name}' no encontrado.\")\n",
    "        return\n",
    "    \n",
    "    serie = df[sensor_name].dropna()\n",
    "    if not pd.api.types.is_datetime64_any_dtype(serie.index):\n",
    "        serie.index = pd.date_range(start='2024-03-15', periods=len(serie), freq='15min')\n",
    "    \n",
    "    if start_date and end_date:\n",
    "        serie = serie.loc[start_date:end_date]\n",
    "    \n",
    "    stl = STL(serie, period=96)\n",
    "    result = stl.fit()\n",
    "    \n",
    "    fig = result.plot()\n",
    "    fig.set_size_inches(14, 8)\n",
    "    fig.suptitle(f\"STL Decomposition (zoom) - {sensor_name}\", fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "# Llamado a la función con rango de fechas\n",
    "plot_stl_zoom('Humidity', start_date='2024-05-01', end_date='2024-05-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ba6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de ACF para cada sensor\n",
    "for sensor in sensor_columns:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plot_acf(df[sensor].dropna(), lags=20, alpha=0.05)\n",
    "    plt.title(f\"ACF de la variable: {sensor}\")\n",
    "    plt.xlabel(\"Lag\")\n",
    "    plt.ylabel(\"Autocorrelación\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba de Dickey-Fuller aumentada para cada sensor y determinacion de estacionariedad\n",
    "for sensor in sensor_columns:\n",
    "    result = adfuller(df[sensor].dropna(), regression='ct')\n",
    "    print(f\"Variable: {sensor}\")\n",
    "    print(f\"ADF Statistic: {result[0]}\")\n",
    "    print(f\"p-value: {result[1]}\")\n",
    "    for key, value in result[4].items():\n",
    "        print(f\"Critical Value {key}: {value}\")\n",
    "    if result[1] < 0.05:\n",
    "        print(f'{sensor} parece ser estacionaria.')\n",
    "    else:\n",
    "        print(f'{sensor} NO es estacionaria.')\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9150ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para realizar la prueba KPSS\n",
    "def kpss_test(series, regression='ct', nlags = \"auto\"):\n",
    "    \"\"\"\n",
    "    Realiza test KPSS sobre una serie y muestra resultados.\n",
    "    \n",
    "    regression: \n",
    "        'c' → solo constante (estacionariedad en nivel)\n",
    "        'ct' → constante y tendencia (estacionariedad en tendencia)\n",
    "    \"\"\"\n",
    "    statistic, p_value, n_lags, critical_values = kpss(series.dropna(), regression=regression, nlags=nlags)\n",
    "    \n",
    "    print(f\"KPSS Statistic: {statistic}\")\n",
    "    print(f\"p-value: {p_value}\")\n",
    "    print(f\"Num Lags: {n_lags}\")\n",
    "    print(\"Critical Values:\")\n",
    "    for key, value in critical_values.items():\n",
    "        print(f\"    {key} : {value}\")\n",
    "        \n",
    "    if p_value < 0.05:\n",
    "        print(\"La serie NO es estacionaria (se rechaza H0).\")\n",
    "    else:\n",
    "        print(\"La serie ES estacionaria (no se rechaza H0).\")\n",
    "\n",
    "# Llamado a la función KPSS para cada sensor\n",
    "for sensor in sensor_columns:\n",
    "    print(f\"\\nVariable: {sensor}\")\n",
    "    kpss_test(df[sensor], regression='ct', nlags=df.shape[0] // 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9362e0a8",
   "metadata": {},
   "source": [
    "# Preparacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7aa7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion de hiperparámetros globales para el modelo\n",
    "umbral = 0.30\n",
    "window_size = 48\n",
    "future_steps = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a613191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMSequencePreprocessor:\n",
    "    def __init__(self, window_size, future_steps):\n",
    "        \"\"\"\n",
    "        window_size: Número de pasos de tiempo hacia atrás para usar como entrada\n",
    "        future_steps: Número de pasos hacia adelante para predecir\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.future_steps = future_steps\n",
    "        self.feature_columns = ['Temperature', 'Vibration', 'Pressure', 'Current', 'Humidity', 'Caudal']\n",
    "        # Un scaler por sensor\n",
    "        self.scalers = {col: StandardScaler() for col in self.feature_columns}\n",
    "    \n",
    "    def fit_transform_sensors(self, data):\n",
    "        \"\"\"Normaliza cada sensor por separado y guarda los scalers\"\"\"\n",
    "        scaled = np.zeros_like(data[self.feature_columns].values, dtype=float)\n",
    "        for i, col in enumerate(self.feature_columns):\n",
    "            scaled[:, i] = self.scalers[col].fit_transform(data[[col]]).flatten()\n",
    "        return scaled\n",
    "    \n",
    "    def transform_sensors(self, data):\n",
    "        \"\"\"Normaliza nuevos datos usando los scalers ya entrenados\"\"\"\n",
    "        scaled = np.zeros_like(data[self.feature_columns].values, dtype=float)\n",
    "        for i, col in enumerate(self.feature_columns):\n",
    "            scaled[:, i] = self.scalers[col].transform(data[[col]]).flatten()\n",
    "        return scaled\n",
    "    \n",
    "    def create_sequences(self, data):\n",
    "        \"\"\"\n",
    "        Convierte datos en secuencias para LSTM sin data leakage, es decir , en la \"y\" del modelo no se incluyen datos futuros de la \"x\"\n",
    "        \"\"\"\n",
    "        # Normalizar cada sensor por separado\n",
    "        sensor_data_scaled = self.fit_transform_sensors(data)\n",
    "        \n",
    "        # Obtener etiquetas de estado\n",
    "        states = data['Unhealthy'].values\n",
    "        \n",
    "        X, y = [], []\n",
    "        \n",
    "        # Crear ventanas temporales\n",
    "        for i in range(self.window_size, len(sensor_data_scaled) - self.future_steps + 1):\n",
    "            X.append(sensor_data_scaled[i-self.window_size:i])\n",
    "            y.append(states[i:i+self.future_steps])\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def transform_new_data(self, data):\n",
    "        \"\"\"\n",
    "        Transforma nuevos datos usando los scalers ya entrenados\n",
    "        \"\"\"\n",
    "        sensor_data_scaled = self.transform_sensors(data)\n",
    "        states = data['Unhealthy'].values\n",
    "        X, y = [], []\n",
    "        for i in range(self.window_size, len(sensor_data_scaled) - self.future_steps + 1):\n",
    "            X.append(sensor_data_scaled[i-self.window_size:i])\n",
    "            y.append(states[i:i+self.future_steps])\n",
    "        return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2897b2",
   "metadata": {},
   "source": [
    "# Modelo de prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_lstm_model(input_shape, future_steps, lstm_units=[80, 32], dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    Crea modelo LSTM para predicción de secuencias futuras\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Primera capa LSTM\n",
    "    model.add(LSTM(lstm_units[0], \n",
    "                   return_sequences=False, \n",
    "                   input_shape=input_shape,\n",
    "                   name='lstm_1'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    " \n",
    "\n",
    "    # Capas densas\n",
    "    model.add(Dense(64, activation='relu', name='dense_1'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    \n",
    "    # Capa de salida - predicción de secuencia futura\n",
    "    model.add(Dense(future_steps, activation='sigmoid', name='output'))\n",
    "    \n",
    "    # Compilar modelo\n",
    "    model.compile(\n",
    "        optimizer= Adam(learning_rate=0.0010),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd1025",
   "metadata": {},
   "source": [
    "# Metricas de evaluacion de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11a80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred, future_steps):\n",
    "    \"\"\"\n",
    "    Evalúa predicciones de secuencias con métricas específicas\n",
    "    \"\"\"\n",
    "    print(\"EVALUACIÓN DE PREDICCIONES DE SECUENCIAS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Métricas por paso de tiempo\n",
    "    step_metrics = []\n",
    "    \n",
    "    for step in range(future_steps):\n",
    "        print(f\"\\nPaso de tiempo {step+1}:\")\n",
    "        \n",
    "        # Extraer predicciones para este paso específico\n",
    "        y_true_step = y_true[:, step]\n",
    "        y_pred_step = y_pred[:, step]\n",
    "        y_pred_binary_step = (y_pred_step > umbral).astype(int)\n",
    "        \n",
    "        # Métricas básicas     \n",
    "        accuracy = accuracy_score(y_true_step, y_pred_binary_step)\n",
    "        precision = precision_score(y_true_step, y_pred_binary_step, zero_division=0)\n",
    "        recall = recall_score(y_true_step, y_pred_binary_step, zero_division=0)\n",
    "        f1 = f1_score(y_true_step, y_pred_binary_step, zero_division=0)\n",
    "        \n",
    "        try:\n",
    "            auc = roc_auc_score(y_true_step, y_pred_step)\n",
    "        except:\n",
    "            auc = 0.5  # Si solo hay una clase\n",
    "        \n",
    "        metrics = {\n",
    "            'step': step + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'auc': auc\n",
    "        }\n",
    "        \n",
    "        step_metrics.append(metrics)\n",
    "        \n",
    "        print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall:    {recall:.4f}\")\n",
    "        print(f\"  F1-Score:  {f1:.4f}\")\n",
    "        print(f\"  AUC:       {auc:.4f}\")\n",
    "    \n",
    "    return step_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9bef5",
   "metadata": {},
   "source": [
    "# Graficas de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history, y_test, y_pred, data, step_metrics):\n",
    "    \"\"\"\n",
    "    Visualizar resultados del entrenamiento para secuencias\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Pérdida durante entrenamiento\n",
    "    plt.subplot(4, 4, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Pérdida durante entrenamiento')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Pérdida')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Accuracy durante entrenamiento\n",
    "    plt.subplot(4, 4, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy durante entrenamiento')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Métricas por paso de tiempo\n",
    "    plt.subplot(4, 4, 3)\n",
    "    steps = [m['step'] for m in step_metrics]\n",
    "    accuracies = [m['accuracy'] for m in step_metrics]\n",
    "    f1_scores = [m['f1'] for m in step_metrics]\n",
    "    aucs = [m['auc'] for m in step_metrics]\n",
    "    \n",
    "    plt.plot(steps, accuracies, 'o-', label='Accuracy', linewidth=2)\n",
    "    plt.plot(steps, aucs, '^-', label='AUC', linewidth=2)\n",
    "    plt.xlabel('Paso futuro')\n",
    "    plt.ylabel('Métrica')\n",
    "    plt.title('Métricas por horizonte de predicción')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Distribución de probabilidades - Primer paso\n",
    "    plt.subplot(4, 4, 4)\n",
    "    plt.hist(y_pred[y_test[:, 0] == 0, 0], bins=30, alpha=0.7, label='Normal', color='blue')\n",
    "    plt.hist(y_pred[y_test[:, 0] == 1, 0], bins=30, alpha=0.7, label='Unhealthy', color='red')\n",
    "    plt.xlabel('Probabilidad predicha')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.title('Distribución probabilidades (Paso 1)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Ejemplos de predicciones de secuencias\n",
    "    sample_indices = np.random.choice(len(y_test), 8, replace=False)\n",
    "    \n",
    "    for idx, sample_idx in enumerate(sample_indices):\n",
    "        plt.subplot(4, 4, 5 + idx)\n",
    "        \n",
    "        steps_range = range(1, len(y_test[sample_idx]) + 1)\n",
    "        \n",
    "        # Valores reales\n",
    "        plt.plot(steps_range, y_test[sample_idx], 'o-', \n",
    "                label='Real', linewidth=2, markersize=6, color='blue')\n",
    "        \n",
    "        # Predicciones\n",
    "        plt.plot(steps_range, y_pred[sample_idx], 's-', \n",
    "                label='Predicho', linewidth=2, markersize=6, color='red', alpha=0.7) \n",
    "        \n",
    "        # Umbral de decisión\n",
    "        plt.axhline(y=umbral, color='orange', linestyle='--', alpha=0.5, label='Umbral')\n",
    "        \n",
    "        plt.xlabel('Paso futuro')\n",
    "        plt.ylabel('Probabilidad/Estado')\n",
    "        plt.title(f'Ejemplo {idx+1}: Secuencia predicha')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.ylim(-0.1, 1.1)\n",
    "    \n",
    "    # Heatmap de correlación temporal\n",
    "    plt.subplot(4, 4, 13)\n",
    "    \n",
    "    # Calcular correlación entre pasos de tiempo\n",
    "    correlation_matrix = np.corrcoef(y_test.T)\n",
    "    \n",
    "    import seaborn as sns\n",
    "    sns.heatmap(correlation_matrix, annot=False, cmap='Greens', center=0,\n",
    "                xticklabels=range(1, y_test.shape[1]+1),\n",
    "                yticklabels=range(1, y_test.shape[1]+1))\n",
    "    plt.title('Correlación entre pasos temporales')\n",
    "    plt.xlabel('Paso futuro')\n",
    "    plt.ylabel('Paso futuro')\n",
    "    \n",
    "    # Precisión vs Horizonte\n",
    "    plt.subplot(4, 4, 14)\n",
    "    precisions = [m['precision'] for m in step_metrics]\n",
    "    recalls = [m['recall'] for m in step_metrics]\n",
    "\n",
    "    plt.plot(steps, precisions, 'o-', label='Precision', linewidth=2, color='green')\n",
    "    plt.plot(steps, recalls, 's-', label='Recall', linewidth=2, color='orange')\n",
    "    plt.plot(steps, f1_scores, '*-', label='F1-Score', linewidth=2, color='blue')\n",
    "    plt.xlabel('Paso futuro')\n",
    "    plt.ylabel('Métrica')\n",
    "    plt.title('Precision vs Recall vs F1-Score por horizonte')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Matriz de confusión para el cuarto paso\n",
    "    plt.subplot(4, 4, 15)\n",
    "    cm = confusion_matrix(y_test[:, 3], (y_pred[:, 3] > umbral).astype(int))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "    xticklabels=['Normal', 'Unhealthy'], yticklabels=['Normal', 'Unhealthy'])\n",
    "    plt.title('Matriz de confusión (Cuarto paso)')\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Realidad\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Matriz de confusión para el décimo paso\n",
    "    plt.subplot(4, 4, 16)\n",
    "    cm = confusion_matrix(y_test[:, 9], (y_pred[:, 9] > umbral).astype(int))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "    xticklabels=['Normal', 'Unhealthy'], yticklabels=['Normal', 'Unhealthy'])\n",
    "    plt.title('Matriz de confusión (décimo paso)')\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Realidad\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d871ae",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar el modelo\n",
    "def train_model():\n",
    "    \"\"\"\n",
    "    Función principal para entrenar y evaluar el modelo de secuencias\n",
    "    \"\"\"\n",
    "    print(\"Realizando asignación de datos...\")\n",
    "    # Se asignan los datos df  a la variable data\n",
    "    data = df\n",
    "    print(\"la data es:\\n \",data.head())\n",
    "\n",
    "\n",
    "    print(f\"Datos cargados: {len(data)} muestras\")\n",
    "    print(f\"Distribución de estados:\")\n",
    "    print(data['Unhealthy'].value_counts())\n",
    "    \n",
    "    # Preparar datos para secuencias\n",
    "    print(\"Preparando datos para LSTM...\")\n",
    "    preprocessor = LSTMSequencePreprocessor(window_size=48, future_steps=12)\n",
    "\n",
    "    X, y = preprocessor.create_sequences(data)\n",
    "\n",
    "    # Inspeccionar las formas de las secuencias\n",
    "    print(\"X shape es:\\n \",X.shape)\n",
    "    print(\"X es:\\n \",X)\n",
    "    print(\"y shape es:\\n \",y.shape)\n",
    "    print(\"y es:\\n \",y)\n",
    "    \n",
    "    print(f\"Forma de X: {X.shape} (samples, window_size, features)\")\n",
    "    print(f\"Forma de y: {y.shape} (samples, future_steps)\")\n",
    "    \n",
    "    # Verificar distribución de clases en diferentes pasos\n",
    "    print(\"Distribución de estados por paso futuro:\")\n",
    "    for step in range( y.shape[1]):  # Mostrar primeros 5 pasos\n",
    "        positive_ratio = np.mean(y[:, step])\n",
    "        print(f\"  Paso {step+1}: {positive_ratio} (proporción de estados unhealthy)\")\n",
    "\n",
    "    # Dividir datos en entrenamiento y test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=SEED\n",
    "    )\n",
    "\n",
    "    # Calculo de pesos de clase para manejar desbalanceo\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train.ravel()),\n",
    "        y=y_train.ravel()\n",
    "    )\n",
    " \n",
    "    weights = dict(zip(np.unique(y_train.ravel()), class_weights))\n",
    "    print(f\"Pesos de clase: {weights}\")\n",
    "\n",
    "    # Crear modelo\n",
    "    print(\"Creando modelo LSTM para secuencias...\")\n",
    "    model = create_sequence_lstm_model(\n",
    "        input_shape=(X.shape[1], X.shape[2]),\n",
    "        future_steps=y.shape[1],\n",
    "    )\n",
    "    \n",
    "    # Resumen del modelo\n",
    "    print(\"Resumen del modelo:\")\n",
    "    model.summary()\n",
    "    print()\n",
    "    \n",
    "    # Callbacks para entrenamiento\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7)\n",
    "    ]\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    print(\"Iniciando entrenamiento de LSTM para predicción de secuencias...\\n\")\n",
    "    print(\"Entrenando modelo...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=150,\n",
    "        batch_size=32,\n",
    "        #class_weight=weights,\n",
    "        class_weight={ 0: weights[0], 1: 2 }, \n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return  data, model, preprocessor, history , X_test, y_test, y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89446080",
   "metadata": {},
   "source": [
    "# Evaluacion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85903dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "def evaluate_model(data, model, X_test, y_test, y_shape, history):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo entrenado con datos de prueba y visualiza los resultados.\n",
    "    \"\"\"\n",
    "    print(\"\\n Evaluando modelo...\")\n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_test)\n",
    "        \n",
    "    # Evaluación específica para secuencias\n",
    "    step_metrics = evaluate_predictions(y_test, y_pred, y_shape)\n",
    "        \n",
    "    # Visualizaciones\n",
    "    plot_results(history, y_test, y_pred, data, step_metrics)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9301252",
   "metadata": {},
   "source": [
    "# Prediccion nuevas secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para predecir nuevas secuencias\n",
    "def predict_new_sequences(model, preprocessor, new_data):\n",
    "    \"\"\"\n",
    "    Hacer predicciones de secuencias sobre nuevos datos\n",
    "    \"\"\"\n",
    "    # Preprocesar nuevos datos\n",
    "    X_new, y_new = preprocessor.transform_new_data(new_data)\n",
    "    \n",
    "    if len(X_new) == 0:\n",
    "        print(\"No hay suficientes datos para hacer predicciones\")\n",
    "        return None\n",
    "    \n",
    "    # Hacer predicciones de secuencias\n",
    "    predictions = model.predict(X_new)\n",
    "    \n",
    "    # Crear DataFrame con resultados\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        base_date = new_data.index[preprocessor.window_size + i]\n",
    "        \n",
    "        for step in range(predictions.shape[1]):\n",
    "            # 15 minutos por paso futuro\n",
    "            future_date = base_date + pd.Timedelta(minutes=15*(step+1))\n",
    "            \n",
    "            results.append({\n",
    "                'Fecha_Base': base_date,\n",
    "                'Fecha_Prediccion': future_date,\n",
    "                'Paso_Futuro': step + 1,\n",
    "                'Probabilidad_Falla': predictions[i, step],\n",
    "                'Estado_Real': y_new[i, step] if i < len(y_new) else None,\n",
    "                'Prediccion_Binaria': int(predictions[i, step] > umbral)  \n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae55279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo\n",
    "data, model, preprocessor, history , X_test, y_test, y_shape = train_model()\n",
    "print(\"\\n Entrenamiento completado!\")\n",
    "print(f\"\\n Modelo entrenado para predecir {preprocessor.future_steps} pasos futuros\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c63869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar modelo y generacion de graficos\n",
    "evaluate_model(data, model, X_test, y_test, y_shape, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25d70b",
   "metadata": {},
   "source": [
    "# Prediccion datos nuevos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar algunos datos nuevos para ejemplo\n",
    "new_data = df_test\n",
    "predictions = predict_new_sequences(model, preprocessor, new_data)\n",
    "print(\"\\n Primeras predicciones de secuencias:\")\n",
    "predictions.head()\n",
    "\n",
    "if predictions is not None:\n",
    "        print(f\"\\n Predicciones generadas: {len(predictions)} registros\")\n",
    "        \n",
    "        # Mostrar algunas predicciones de ejemplo\n",
    "        print(\"\\n Ejemplo de predicciones de secuencia (intervalo de 15 minutos):\")\n",
    "        sample_base_date = predictions['Fecha_Base'].iloc[0]\n",
    "        sample_predictions = predictions[predictions['Fecha_Base'] == sample_base_date]\n",
    "        \n",
    "        print(f\"\\nPredicciones desde: {sample_base_date}\")\n",
    "        for _, row in sample_predictions.head(12).iterrows():\n",
    "            print(f\"  Paso {row['Paso_Futuro']:2d}: \"\n",
    "                  f\"{row['Fecha_Prediccion'].strftime('%H:%M')} -> \"\n",
    "                  f\"Prob: {row['Probabilidad_Falla']:.3f} \"\n",
    "                  f\"({'UNHEALTHY' if row['Prediccion_Binaria'] else 'NORMAL':8s})\")\n",
    "        \n",
    "        # Estadísticas de riesgo\n",
    "        high_risk = predictions[predictions['Probabilidad_Falla'] > umbral]\n",
    "        print(f\"\\n Predicciones de alto riesgo (>{umbral *100}%): {len(high_risk)}\")\n",
    "        \n",
    "        if len(high_risk) > 0:\n",
    "            print(\"\\n Primeros períodos de mayor riesgo (intervalo de 15 minutos):\")\n",
    "            risk_summary = high_risk.groupby('Fecha_Prediccion')['Probabilidad_Falla'].max().sort_values(ascending=False)\n",
    "            print(risk_summary.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab91c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictions is not None and len(predictions) > 0:\n",
    "    # Seleccionar una fecha base de ejemplo\n",
    "    sample_base_date = predictions['Fecha_Base'].iloc[0]\n",
    "    sample_predictions = predictions[predictions['Fecha_Base'] == sample_base_date]\n",
    "    \n",
    "    # Fechas de predicción\n",
    "    fechas_pred = sample_predictions['Fecha_Prediccion']\n",
    "    # Probabilidad predicha\n",
    "    prob_pred = sample_predictions['Probabilidad_Falla']\n",
    "    # Estado real\n",
    "    estado_real = sample_predictions['Estado_Real']\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(fechas_pred, estado_real, 'o-', label='Real (Unhealthy)', color='blue')\n",
    "    plt.plot(fechas_pred, prob_pred, 's-', label='Predicción (Probabilidad de Falla)', color='red')\n",
    "    plt.axhline(y=umbral, color='orange', linestyle='--', label=f'Umbral {umbral}')\n",
    "    plt.xlabel('Fecha de Predicción')\n",
    "    plt.ylabel('Estado / Probabilidad')\n",
    "    plt.title('Comparación: Estado real vs Predicción de probabilidad de falla')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No hay predicciones para graficar.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar 4 ejemplos de predicción vs real para diferentes fechas base de manera aleatoria\n",
    "if predictions is not None and len(predictions) > 0:\n",
    "    unique_bases = predictions['Fecha_Base'].unique()\n",
    "    random_bases = np.random.choice(unique_bases, size=min(4, len(unique_bases)), replace=False)\n",
    "    #random_bases = risk_summary.head()\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 8))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i, base_date in enumerate(random_bases):\n",
    "        sample_predictions = predictions[predictions['Fecha_Base'] == base_date]\n",
    "        fechas_pred = sample_predictions['Fecha_Prediccion']\n",
    "        prob_pred = sample_predictions['Probabilidad_Falla']\n",
    "        estado_real = sample_predictions['Estado_Real']\n",
    "        \n",
    "        axs[i].plot(fechas_pred, estado_real, 'o-', label='Real (Unhealthy)', color='blue')\n",
    "        axs[i].plot(fechas_pred, prob_pred, 's-', label='Predicción (Probabilidad de Falla)', color='red')\n",
    "        axs[i].axhline(y=umbral, color='orange', linestyle='--', label=f'Umbral {umbral}')\n",
    "        axs[i].set_xlabel('Fecha de Predicción')\n",
    "        axs[i].set_ylabel('Estado / Probabilidad')\n",
    "        axs[i].set_title(f'Ejemplo {i+1}: Base {base_date}')\n",
    "        axs[i].legend()\n",
    "        axs[i].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maestria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
